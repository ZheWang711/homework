# 250b-hw3

##Question 5

(A) 

* Create the validation set: randomly pick 10000 images from the test data set, the validation set will be used to compute $$c$$.
* Prediction rule: let $$X$$ be the set of images, and $$Y$$ be the the class, the prediction rule will be: $$argmax_t(P(y=t|x))$$.


**Pseudo code:**

* Randomly choose 10000 images from test data as validation set.
* **First train**: train the model based on the remaining 50000 images of the test set.
    * For each digit $$i$$, let $$X^{(i)}$$ be its corresponding images ($$X^{(i)}$$ is a matrix, each row of it is an image vector, and each column of $$X^{(i)}$$ corresponds with a particular pixel), $$m$$ is the number of rows in that matrix (the number of images corresponding with digit $$i$$).
        * compute $$\mu = \frac{\text{sum of col}(X^{(i)})}{m}$$.
        * compute covariance matrix $$\Sigma = \frac{X^{(i)T}X^{(i)}}{m}$$

* **validate**(c): try different values of c, find out the one with smallest error rate.
    * $$\Sigma' = \Sigma + cI$$
    * Since  
    $$argmax_y{P(y|x)} = argmax\frac{P(x|y)P(y)}{P(x)} = argmax_y\{logP(x|y)) + logP(y)\} $$.  
    Then for each digit i, compute its corresponding log-probability predict the one whose value is the largest:
        * $$logP(x|y)=-\frac{p*log(2\pi)}{2} - \frac{log\Sigma'}{2} - \frac{1}{2}(x-\mu)^T\Sigma^{'-1}(x-\mu)$$
        * $$logP(y) = log\frac{\text{num of digit i}}{\text{length of train set}}$$
        
    * compare the prediction with the correct label
    * compute and return the error rate



* **Second Train:** By performing several above validation process, let $$cc$$ be the one with smallest validate error.
    * Instead of using the remaining 50000 training data, use the entire 60000 training data at this time.
        * For each digit $$i$$, let $$X^{'(i)}$$ be its corresponding images, $$m'$$ is the number of rows in that matrix (the number of images corresponding with digit $$i$$)
    * compute $$\mu = \frac{\text{sum of col}(X^{'(i)})}{m'}$$.
    * compute covariance matrix $$\Sigma = \frac{X^{'(i)T}X^{'(i)}}{m'} + ccI$$

(B)

Validation error vs. $$c$$

![](Unknown-7)

Thus we choose $$c$$ as $$3000$$, and the test error is $$4.447\%$$

(C)

**Instance 1:**
* Display

![](Unknown)

* Posterior probability

prediction: 3
answer: 2

| $$y$$ | $$P(y|x)$$ |
| -- | -- |
| 0 | 3.166511770469642e-12 |
| 1 | 4.3364505260927414e-89 |
| 2 | 0.0014696796995697535 |
| 3 | 0.9985303202829148 |
| 4 | 1.187052411384596e-54 |
| 5 | 3.234767760880538e-19 |
| 6 | 1.2837938589609495e-32 |
| 7 | 7.682465562235285e-89 |
| 8 | 1.4083727171727586e-11 |
| 9 | 5.541401348615013e-53 |

 
**Instance 2:** 

* Display


![](Unknown-3)

* Posterior probability

prediction: 1
answer: 6

| $$y$$ | $$P(y|x)$$ |
| -- | -- |
| 0 | 4.5023674503345905e-40 |
| 1 | 0.9999999994633981 |
| 2 | 3.340665260505071e-28 |
| 3 | 8.300759794627006e-26 |
| 4 | 2.9096611592167635e-32 |
| 5 | 4.81008806109596e-30 |
| 6 | 5.368882466313778e-10 |
| 7 | 3.2638073863665774e-54 |
| 8 | 6.739059102297456e-19 |
| 9 | 2.3570264779094618e-55 |

**Instance 3**


![](Unknown-4)

* Posterior probability

* Display prediction: 1
answer: 7

| $$y$$ | $$P(y|x)$$ |
| -- | -- |
| 0 | 1.0233792246126153e-52 |
| 1 | 1.0 |
| 2 | 4.7190567449808085e-32 |
| 3 | 3.065794765662978e-32 |
| 4 | 8.838139931691335e-21 |
| 5 | 1.0398698386711265e-42 |
| 6 | 1.8328455531772348e-44 |
| 7 | 8.455274384606583e-23 |
| 8 | 1.4474168812517608e-23 |
| 9 | 9.489867784174749e-21 |

**Instance 4**
* Display 


![](Unknown-8)

* Posterior probability

prediction: 5
answer: 3

| $$y$$ | $$P(y|x)$$ |
| -- | -- |
| 0 | 2.4306369626898952e-20 |
| 1 | 1.4630642722275437e-104 |
| 2 | 1.1713639024652891e-18 |
| 3 | 6.612040407725631e-10 |
| 4 | 9.559159428088026e-24 |
| 5 | 0.9999999993387974 |
| 6 | 3.40019017139348e-32 |
| 7 | 1.2444641868525916e-73 |
| 8 | 8.024865278369408e-27 |
| 9 | 5.482371416858694e-46 |
**Instance 5**

* Display 


![](Unknown-6)
* Posterior probability

prediction: 2
answer: 9

| $$y$$ | $$P(y|x)$$ |
| -- | -- |
| 0 | 1.3861638707072283e-12 |
| 1 | 1.7635675791641236e-250 |
| 2 | 0.9999999996662154 |
| 3 | 3.315387139741261e-10 |
| 4 | 2.181639533586354e-65 |
| 5 | 1.5289906019095007e-12 |
| 6 | 1.1664111968086499e-75 |
| 7 | 1.6493566228409604e-61 |
| 8 | 1.13597837384623e-19 |
| 9 | 1.3809569394481843e-26 |


## Question 6

(a) 

My new prediction strategy use a *threshold* to determine if the classifier should abstain or not. The relationship of *threshold* and *f* is built by validation set, based on the assumption that validation set and testing set should be similar.


* Separate the tran-data into 2 data sets: training set (50000 images) and validation set (10000 images)
* Use training set to train a model, with additional calculating *delta*. `delta[i]` is the difference between the first largest log-probability with the second largest log-probability for `image[i]`.
* Build the relationship between "f" and "threshold":
    * sort the delta array in ascending order.
    * $$\Delta(f) \rightarrow delta[m*f] $$, where m is the number of images in validation set (10000).
* Predict and test on testing data:
    * For each image, computes its corresponding delta, if it is smaller than $$\Delta(f)$$, then abstain, otherwise make the prediction same as above (by $$argmax_y{P(y|x)}$$).

(b) Pseudo code
```Python
# First training
model, Pi = build_model(train_img[:50000], train_lab[:50000])

def get_delta(test: np.array, model, Pi, c=3000) -> np.array:
    log_prob = np.array(
                [multivariate_normal.logpdf(
                    test, model[i].mu, model[i].sigma + c*np.identity(
                        len(model[i].sigma))) 
                        for i in range(10)
                ]
               )
    
    log_Pi = np.log(np.array(Pi))
    log_prob = (log_prob.T+log_Pi).T
    lgs = np.sort(log_prob, axis=0)
    return np.sort(lgs[-1] - lgs[-2])

def get_f(threshold, deltas):
    abstain = 0
    for x in deltas:
        if x < threshold:
            abstain += 1
    return abstain / 10000
    
def f_to_threshold(f: float, deltas: np.array):
    cnt = int(f * len(deltas))
    return deltas[cnt]


deltas0 = get_delta(train_img[50000:], model, Pi)

fs = [0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

    
model, Pi = build_model(train_img, train_lab)

def test_data_with_abstain(f: float) -> float:
    test_img, test_lab =\
    random_shuffle(test_length, len(test_vector), test_vector, test_labels)
    err = 0
    abstain = 0
    prediction = predict(3000, model, test_img, Pi)
    deltas = get_delta(test_img, model, Pi)
    for i in range(10000):
        if deltas[i] < f_to_threshold(f, deltas0):
            abstain += 1
        elif prediction[i] != test_lab[i]:
            err += 1
    return err / 10000, abstain / 10000


result = [test_data_with_abstain(f) for f in fs]
error = [r[0] for r in result]
abstain = [r[1] for r in result]
plot(fs, error)
plot(fs, abstain)

```
(c)

* test error rate versus f

![](Unknown-11)
  
* abstain fraction versus f
![](Unknown-12)



